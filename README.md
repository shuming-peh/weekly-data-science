# Introduction to Data Science

## Course Description
This course is split into 2 parts:
1. Mathematical and statistical foundation
1. Derivation of how each algorithm works
	- How each algorithm works, and what are important to the algorithm
	- The advantages and limits of each algorithm

This course covers the mathematical basics and concepts (and derivation) of what goes behind each algorithm and provide a sound foundation and understanding of what each model or algorithm does. The notions of calculus, mathematical theories and assumptions are explained. These notions then form the bases and build up to each algorithm that will be taught in this course.

## Learning Objectives 
By the end of this course, you will be able to:
- Use techniques and theorems from calculus to solve basic problems, such as optimization and functional approximation
- Use the concepts taught to read, appreciate and understand foundational Machine Learning literature
- Use the concepts taught to apply to and solve real world problems using data science (or mathematics/statistics)

## Pre-Requisite Knowledge
No pre-requisite knowledge is required, everything will be covered in class. Even if you have no knowledge in calculus, it will be re-taught in class.

## Class Timings
Every Saturday, 1030 â€“ 1330 (ish)
39 Robinson Road, Level 9, Potala

## Recommended Text and Readings
Any good advanced calculus textbook will be useful as supplementary reading
- Understanding Machine Learning: From Theory to Algorithms; Shai Shalev-Shwartz and Shai Ben-David
- Elementary Linear Algebra, Howard Anton
- Numerical Analysis, Timothy Sauer
- A First Course in Differential Equations, Brooks/Cole
- Time Series Analysis, Jan Grandell
- Time Series Analysis and Its Applications, Robert H. Shumway and David S. Stoffer

## Lesson Plans (and how does everything tie in together)
|Lesson No.   |Specific Learning Objective for the Lesson   |Topics Covered   |Which Topic does it Relate to   |
|---		  |---											|---			  |---							   |
|1   |Intro to Basic Python   |<ul><li>Installation of python and jupyter notebook</li><li>Installation of python packages</li><li>Basic syntax</li><li>Basic string manipulations</li></ul>  |<ul><li>Used in coding</li></ul> |
|2   |Intro to Pandas and Visualization   |<ul><li>Basic data manipulation and wrangling and transformation</li><li>Basic creation of functions</li><li>Basic visualization of data</li></ul>   |<ul><li>Used in coding</li></ul>   |
|3   |Intro to Python Class Files   |<ul><li>Creation of python class files</li><li>Basic idea of code modularization with class files</li></ul>   |<ul><li>Used in coding</li></ul>   |
|4   |Intro to SQL and Version Control   |<ul><li>SQL syntax</li><li>Join, union, window functions, having and with clauses</li><li>Introduction of Git and setup (SSH)</li></ul>   |<ul><li>Used in data extraction and basic transformation</li><li>Git is used in storage of files and tracking of progress</li></ul>   |
|5   |Intro to Statistics and Probability Theory   |<ul><li>Intro to distributions</li><li>Intro to probability theory and assumptions</li><li>Intro to statistical testing</li><li>Intro to MLE</li><li>Intro to MGF</li></ul>   |<ul><li>Used in ML algorithms</li><li>ML algorithms have underlying distributions like Normal or exponential distribution</li><li>Getting the parameters of ML algos, MLE is often used</li></ul>   |
|6   |Intro to Linear Regression*   |<ul><li>Intro to univariate</li><li>Intro to the loss function</li><li>Intro to getting parameters of regression using MLE</li><li>Intro to R-square, and adjusted R-square</li><li>Intro to variables significance</li><li>Intro to multiple regression</li></ul>   |<ul><li>Loss function is the objective function for ML algos</li><li>Linear regression is also a machine learning algo</li></ul>   |
|7   |Intro to Linear Algebra*   |<ul><li>Intro to basic properties of matrices and vector spaces</li><li>Intro to solving system of linear equations with LA</li><li>Intro to eigen values/vectors</li><li>Intro to orthogonal</li><li>Intro to PCA</li><li>Intro to matrix factorization</li></ul>   |<ul><li>LA can also be used to solve linear regression</li><li>LA is often used in dimension reduction</li><li>LA links to ML algo like SVM and recommendation systems</li></ul>   |
|8   |Intro to Time Series Analysis*   |<ul><li>Intro to stationary and non stationary series</li><li>Intro to stationary tests</li><li>Intro to ARIMA</li><li>Intro to exponential smoothing</li><li>Intro to state space models (BSTS)</li><li>Intro to distribution forecasting</li><li>Intro to probabilistic forecasting</li></ul>   |<ul><li>Not everything needs to be solved by ML</li></ul>   |
|9   |Intro to Optimization and Numerical Methods*   |<ul><li>Intro to different optimization methods</li><li>Intro to splines</li><li>Intro to gradient descent</li><li>Intro to stochastic gradient descent</li></ul>   |<ul><li>Solving for loss function or the intuition of the loss function</li></ul>   |
|10   |Intro to Classical Machine Learning Algorithms*   |<ul><li>Intro to supervised and unsupervised learning</li><li>Intro to unsupervised learning (clustering)</li><li>Intro to supervised learning</li><ul><li>Linear regression</li><li>Logistics regression</li><li>Generalized linear model</li><li>Regularization</li><li>Support Vector Machine (SVM)</li><li>Linear Discriminant Analysis</li><li>Nearest Neighbour</li><li>Decision Trees</li><li>Bagging</li><li>Boosting</li><li>Gradient Boosting</li></ul></ul>  |<ul><li>What is learnt above will be applied to here</li></ul>   |
|11   |Intro to Recommendation Systems*   |<ul><li>Intro to supervised and unsupervised learning</li><li>Intro to unsupervised learning (clustering)</li><li>Intro to supervised learning</li><ul><li>Linear regression</li><li>Logistics regression</li><li>Generalized linear model</li><li>Regularization</li><li>Support Vector Machine (SVM)</li><li>Linear Discriminant Analysis</li><li>Nearest Neighbour</li><li>Decision Trees</li><li>Bagging</li><li>Boosting</li><li>Gradient Boosting</li></ul></ul>  |<ul><li>What is learnt above will be applied to here</li></ul>   |
|12   |Intro to Neural Networks*   |<ul><li>Intro to NN</li><li>Intro to cNN, rNN and dNN (Deep learning)</li></ul>   |<ul><li>Gradient descent</li><li>Everything else above</li><li>Differential equations</li></ul>   |
*Code will be shown appropriately
